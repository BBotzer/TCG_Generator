{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Testing of a Decoder-only (GPT style) architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, processors\n",
    "from tokenizers.normalizers import NFKC, Sequence\n",
    "import os\n",
    "from typing import List, Optional, Union\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "import transformers\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import Dataset, DatasetDict,load_dataset #, load_metric\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "import ast # Because the tokenized_text column data is stored as a string instead of a list...\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check tensforflow GPU availability\n",
    "# print(tf.config.list_physical_devices(device_type='GPU'))\n",
    "\n",
    "# It looks like Brandon's rig hates him right now... stupid WSL2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are usisng cuda on a NVIDIA GeForce GTX 1070.\n"
     ]
    }
   ],
   "source": [
    "# Check pytorch GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'You are usisng {device} on a {torch.cuda.get_device_name()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Get the dataset\n",
    "2) Fix the tokenize_text column from a string to a list of strings\n",
    "3) Pull out all of the words into a mega-list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOMTHING IS WRONG WITH THE DATASET.  Likely an issue with the preprocessing steps...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the processed card data from wherever you have it.\n",
    "\n",
    "# df = pd.read_csv('../data/processed/mtg_carddata_processed.csv')\n",
    "df = pd.read_csv('../data/processed/mtg_carddata_processed_2_23_25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mana_cost</th>\n",
       "      <th>type_line</th>\n",
       "      <th>oracle_text</th>\n",
       "      <th>power</th>\n",
       "      <th>toughness</th>\n",
       "      <th>colors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>mtgo_id</th>\n",
       "      <th>loyalty</th>\n",
       "      <th>defense</th>\n",
       "      <th>processed_oracle_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>tfidf_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nissa, Worldsoul Speaker</td>\n",
       "      <td>{3}{G}</td>\n",
       "      <td>Legendary Creature — Elf Druid</td>\n",
       "      <td>Landfall — Whenever a land you control enters,...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>['G']</td>\n",
       "      <td>['Landfall']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Landfall — Whenever a land you control enters ...</td>\n",
       "      <td>['Landfall', 'Whenever', 'a', 'land', 'you', '...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Static Orb</td>\n",
       "      <td>{3}</td>\n",
       "      <td>Artifact</td>\n",
       "      <td>As long as &lt;name&gt; is untapped, players can't u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>15870.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As long as Static Orb is untapped , players ca...</td>\n",
       "      <td>['As', 'long', 'as', '&lt;name&gt;', 'is', 'untapped...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sensory Deprivation</td>\n",
       "      <td>{U}</td>\n",
       "      <td>Enchantment — Aura</td>\n",
       "      <td>Enchant creature\\r\\nEnchanted creature gets -3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['U']</td>\n",
       "      <td>['Enchant']</td>\n",
       "      <td>49283.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enchant creature \\n Enchanted creature gets -3...</td>\n",
       "      <td>['Enchant', 'creature', '\\\\n', 'Enchanted', 'c...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Road of Return</td>\n",
       "      <td>{G}{G}</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Choose one —\\r\\n• Return target permanent card...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['G']</td>\n",
       "      <td>['Entwine']</td>\n",
       "      <td>77122.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Choose one — \\n • Return target permanent card...</td>\n",
       "      <td>['Choose', 'one', '\\\\n', 'Return', 'target', '...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Storm Crow</td>\n",
       "      <td>{1}{U}</td>\n",
       "      <td>Creature — Bird</td>\n",
       "      <td>Flying (This creature can't be blocked except ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>['U']</td>\n",
       "      <td>['Flying']</td>\n",
       "      <td>22609.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Flying (This creature can't be blocked except ...</td>\n",
       "      <td>['Flying', 'This', 'creature', \"can't\", 'be', ...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Snarlfang Vermin</td>\n",
       "      <td>{B}</td>\n",
       "      <td>Creature — Rat</td>\n",
       "      <td>Whenever &lt;name&gt; deals combat damage to a creat...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>['B']</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whenever Snarlfang Vermin deals combat damage ...</td>\n",
       "      <td>['Whenever', '&lt;name&gt;', 'deals', 'combat', 'dam...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Walking Sponge</td>\n",
       "      <td>{1}{U}</td>\n",
       "      <td>Creature — Sponge</td>\n",
       "      <td>{T}: Target creature loses your choice of flyi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['U']</td>\n",
       "      <td>[]</td>\n",
       "      <td>12637.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{T} : Target creature loses your choice of fly...</td>\n",
       "      <td>['{T}', ':', 'Target', 'creature', 'loses', 'y...</td>\n",
       "      <td>[0. 0. 0. ... 0. 0. 0.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name mana_cost                       type_line  \\\n",
       "0  Nissa, Worldsoul Speaker    {3}{G}  Legendary Creature — Elf Druid   \n",
       "1                Static Orb       {3}                        Artifact   \n",
       "2       Sensory Deprivation       {U}              Enchantment — Aura   \n",
       "3            Road of Return    {G}{G}                         Sorcery   \n",
       "4                Storm Crow    {1}{U}                 Creature — Bird   \n",
       "5          Snarlfang Vermin       {B}                  Creature — Rat   \n",
       "6            Walking Sponge    {1}{U}               Creature — Sponge   \n",
       "\n",
       "                                         oracle_text power toughness colors  \\\n",
       "0  Landfall — Whenever a land you control enters,...     3         3  ['G']   \n",
       "1  As long as <name> is untapped, players can't u...   NaN       NaN     []   \n",
       "2  Enchant creature\\r\\nEnchanted creature gets -3...   NaN       NaN  ['U']   \n",
       "3  Choose one —\\r\\n• Return target permanent card...   NaN       NaN  ['G']   \n",
       "4  Flying (This creature can't be blocked except ...     1         2  ['U']   \n",
       "5  Whenever <name> deals combat damage to a creat...     2         1  ['B']   \n",
       "6  {T}: Target creature loses your choice of flyi...     1         1  ['U']   \n",
       "\n",
       "       keywords  mtgo_id loyalty  defense  \\\n",
       "0  ['Landfall']      NaN     NaN      NaN   \n",
       "1            []  15870.0     NaN      NaN   \n",
       "2   ['Enchant']  49283.0     NaN      NaN   \n",
       "3   ['Entwine']  77122.0     NaN      NaN   \n",
       "4    ['Flying']  22609.0     NaN      NaN   \n",
       "5            []      NaN     NaN      NaN   \n",
       "6            []  12637.0     NaN      NaN   \n",
       "\n",
       "                               processed_oracle_text  \\\n",
       "0  Landfall — Whenever a land you control enters ...   \n",
       "1  As long as Static Orb is untapped , players ca...   \n",
       "2  Enchant creature \\n Enchanted creature gets -3...   \n",
       "3  Choose one — \\n • Return target permanent card...   \n",
       "4  Flying (This creature can't be blocked except ...   \n",
       "5  Whenever Snarlfang Vermin deals combat damage ...   \n",
       "6  {T} : Target creature loses your choice of fly...   \n",
       "\n",
       "                                      tokenized_text             tfidf_vector  \n",
       "0  ['Landfall', 'Whenever', 'a', 'land', 'you', '...  [0. 0. 0. ... 0. 0. 0.]  \n",
       "1  ['As', 'long', 'as', '<name>', 'is', 'untapped...  [0. 0. 0. ... 0. 0. 0.]  \n",
       "2  ['Enchant', 'creature', '\\\\n', 'Enchanted', 'c...  [0. 0. 0. ... 0. 0. 0.]  \n",
       "3  ['Choose', 'one', '\\\\n', 'Return', 'target', '...  [0. 0. 0. ... 0. 0. 0.]  \n",
       "4  ['Flying', 'This', 'creature', \"can't\", 'be', ...  [0. 0. 0. ... 0. 0. 0.]  \n",
       "5  ['Whenever', '<name>', 'deals', 'combat', 'dam...  [0. 0. 0. ... 0. 0. 0.]  \n",
       "6  ['{T}', ':', 'Target', 'creature', 'loses', 'y...  [0. 0. 0. ... 0. 0. 0.]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Landfall', 'Whenever', 'a', 'land', 'you', 'control', 'enters', ',', 'you', 'get', '{E}', '{E}', 'two', 'energy', 'counters', '.', '\\\\\\\\n', 'You', 'may', 'pay', 'eight', '{E}', 'rather', 'than', 'pay', 'the', 'mana', 'cost', 'for', 'permanent', 'spells', 'you', 'cast', '.']\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Landfall, Whenever, a, land, you, control, en...\n",
       "1    [As, long, as, <name>, is, untapped, ,, player...\n",
       "2    [Enchant, creature, \\n, Enchanted, creature, g...\n",
       "3    [Choose, one, \\n, Return, target, permanent, c...\n",
       "4    [Flying, This, creature, can't, be, blocked, e...\n",
       "5    [Whenever, <name>, deals, combat, damage, to, ...\n",
       "6    [{T}, :, Target, creature, loses, your, choice...\n",
       "7            [Exile, all, multicolored, permanents, .]\n",
       "8    [When, <name>, enters, ,, create, a, Food, tok...\n",
       "9    [<name>, deals, damage, to, any, target, equal...\n",
       "Name: tokenized_text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply ast.literal_eval to each row in the tokenized_text column\n",
    "df['tokenized_text'] = df['tokenized_text'].apply(ast.literal_eval)\n",
    "\n",
    "# Display first few rows to verify\n",
    "df['tokenized_text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Landfall'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_text'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 968000\n",
      "First 20 tokens: ['Landfall', 'Whenever', 'a', 'land', 'you', 'control', 'enters', ',', 'you', 'get', '{E}', '{E}', 'two', 'energy', 'counters', '.', '\\\\n', 'You', 'may', 'pay']\n"
     ]
    }
   ],
   "source": [
    "# Combine all tokens into one large list\n",
    "all_tokens = []\n",
    "for tokens in df['tokenized_text']:\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "# Alternative one-liner using list comprehension\n",
    "# all_tokens = [token for tokens in df['tokenized_text'] for token in tokens]\n",
    "\n",
    "# Display the first 20 tokens to verify\n",
    "print(f\"Total tokens: {len(all_tokens)}\")\n",
    "print(\"First 20 tokens:\", all_tokens[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Landfall — Whenever a land you control enters ...\n",
       "1        As long as Static Orb is untapped , players ca...\n",
       "2        Enchant creature \\n Enchanted creature gets -3...\n",
       "3        Choose one — \\n • Return target permanent card...\n",
       "4        Flying (This creature can't be blocked except ...\n",
       "                               ...                        \n",
       "30618                                                  NaN\n",
       "30619    Target creature you control gains indestructib...\n",
       "30620    Red instant and sorcery spells you control hav...\n",
       "30621    +1 : Up to one target creature gains double st...\n",
       "30622                     All Sliver creatures get +1/+1 .\n",
       "Name: processed_oracle_text, Length: 30623, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = df['processed_oracle_text']\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert corpus to list of strings if it's not already\n",
    "corpus_list = corpus.tolist() if hasattr(corpus, 'tolist') else list(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Landfall — Whenever a land you control enters ...\n",
      "1    As long as Static Orb is untapped , players ca...\n",
      "2    Enchant creature \\n Enchanted creature gets -3...\n",
      "Name: processed_oracle_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas Series to list of strings\n",
    "corpus_list = corpus.values.tolist()\n",
    "\n",
    "# Ensure all elements are strings\n",
    "corpus_list = [str(text) for text in corpus_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Landfall — Whenever a land you control enters , you get {E} {E} (two energy counters) . \\\\n You may pay eight {E} rather than pay the mana cost for permanent spells you cast .'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(corpus_list))  # Should show: <class 'list'>\n",
    "print(type(corpus_list[0]))  # Should show: <class 'str'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train/val/test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do we need to keep other information with the corpus_list as we split it up?  Names, color, etc.?\n",
    "\n",
    "If we're just generating text, I think that answer is no.  If we want more, then the answer is likely yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, temp = train_test_split(corpus_list, test_size=0.2, random_state=42) # Set 80% for training\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=42) # Set 10% for validation and 10% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [{\"sentence\": text} for text in train_list]  # Wrap each sentence in a dict\n",
    "val = [{\"sentence\": text} for text in val]\n",
    "test = [{\"sentence\": text} for text in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DatasetDict({\n",
    "    'train': Dataset.from_list(train),\n",
    "    'validation': Dataset.from_list(val),\n",
    "    'test': Dataset.from_list(test)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['Choose one — \\\\n • Destroy target Cleric . \\\\n • Return target Cleric card from your graveyard to your hand . \\\\n • Target player loses 2 life .',\n",
       "  '( {T} : Add {W} or {B} . )',\n",
       "  'Explosive Welcome deals 5 damage to any target and 3 damage to any other target . Add {R} {R} {R} .',\n",
       "  \"Vigilance (Attacking doesn't cause this creature to tap . )\",\n",
       "  \"Trample \\\\n Alexios , Deimos of Kosmos attacks each combat if able , can't be sacrificed , and can't attack its owner . \\\\n At the beginning of each player's upkeep , that player gains control of Alexios , untaps it , and puts a +1/+1 counter on it . It gains haste until end of turn .\"]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence'],\n",
       "    num_rows: 24498\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flash \\\\n Other white creatures you control get +1/+1 . \\\\n Other blue creatures you control get +1/+1 .'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['validation']['sentence'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Tokenizer on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for tokenizer files if it doesn't exist\n",
    "models_dir = \"../models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpt2_tokenizer(vocab_size=50257, min_frequency=2):\n",
    "    \"\"\"\n",
    "    Create a GPT2-style BPE tokenizer from scratch using Hugging Face tokenizers library.\n",
    "\n",
    "    Args:\n",
    "        vocab_size: The size of the vocabulary to learn\n",
    "        min_frequency: Minimum frequency for a token to be considered in the BPE algorithm\n",
    "\n",
    "    Returns:\n",
    "        A tokenizer object ready for training\n",
    "    \"\"\"\n",
    "    # Initialize a ByteLevelBPE model-based tokenizer\n",
    "    tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "    # Add byte-level pre-tokenizer\n",
    "    tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "\n",
    "    # Add decoder to properly decode byte-level tokens\n",
    "    tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "    # Set up normalizers - GPT-2 doesn't do much normalization\n",
    "    tokenizer.normalizer = Sequence([NFKC()])\n",
    "\n",
    "    # Return the tokenizer (to be trained later)\n",
    "    return tokenizer\n",
    "\n",
    "def train_tokenizer_from_texts(\n",
    "    tokenizer: Tokenizer,\n",
    "    texts: List[str],\n",
    "    vocab_size: int = 8192,\n",
    "    min_frequency: int = 2,\n",
    "    batch_size: int = 512,\n",
    "    output_dir: str = \"tokenizer\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the tokenizer on a list of texts using batching\n",
    "\n",
    "    Args:\n",
    "        tokenizer: The tokenizer object to train\n",
    "        texts: List of strings to use for training\n",
    "        vocab_size: Maximum vocabulary size\n",
    "        min_frequency: Minimum frequency for a token\n",
    "        batch_size: Number of texts to process in each batch\n",
    "        output_dir: Directory to save the trained tokenizer\n",
    "\n",
    "    Returns:\n",
    "        The trained tokenizer\n",
    "    \"\"\"\n",
    "    if not texts:\n",
    "        raise ValueError(\"No texts provided for training\")\n",
    "\n",
    "    # Configure the BPE trainer\n",
    "    trainer = trainers.BpeTrainer(\n",
    "        vocab_size=vocab_size,\n",
    "        min_frequency=min_frequency,\n",
    "        special_tokens=[\"<|endoftext|>\", \"<|pad|>\"],\n",
    "        show_progress=True,\n",
    "    )\n",
    "\n",
    "    # Create temporary files for batched training\n",
    "    temp_dir = os.path.join(output_dir, \"temp\")\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    # Split texts into batches\n",
    "    batches = [texts[i:i+batch_size] for i in range(0, len(texts), batch_size)]\n",
    "    batch_files = []\n",
    "\n",
    "    print(f\"Preparing {len(batches)} batches for training...\")\n",
    "\n",
    "    # Write batches to temporary files\n",
    "    for i, batch in enumerate(tqdm(batches)):\n",
    "        batch_file = os.path.join(temp_dir, f\"batch_{i}.txt\")\n",
    "        with open(batch_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n<|endoftext|>\\n\".join(batch))\n",
    "            f.write(\"\\n<|endoftext|>\\n\")  # Add final separator\n",
    "        batch_files.append(batch_file)\n",
    "\n",
    "    # Train the tokenizer\n",
    "    print(\"Training tokenizer...\")\n",
    "    tokenizer.train(batch_files, trainer)\n",
    "\n",
    "    # Add post-processor to handle special tokens\n",
    "    tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n",
    "\n",
    "    # Enable padding with the PAD token\n",
    "    pad_id = tokenizer.token_to_id(\"<|pad|>\")\n",
    "    if pad_id is not None:\n",
    "        tokenizer.enable_padding(pad_id=pad_id, pad_token=\"<|pad|>\")\n",
    "    else:\n",
    "        print(\"Warning: <|pad|> token not found in vocabulary. Padding won't work correctly.\")\n",
    "\n",
    "    # Save the trained tokenizer\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    tokenizer.save(f\"{output_dir}/gpt2_tokenizer.json\")\n",
    "\n",
    "    # Clean up temporary files\n",
    "    for file in batch_files:\n",
    "        os.remove(file)\n",
    "    os.rmdir(temp_dir)\n",
    "\n",
    "    print(f\"Tokenizer trained and saved to {output_dir}/gpt2_tokenizer.json\")\n",
    "    return tokenizer\n",
    "\n",
    "def use_tokenizer(tokenizer, text, padding=True, max_length=None):\n",
    "    \"\"\"\n",
    "    Demonstrate how to use the tokenizer with padding\n",
    "\n",
    "    Args:\n",
    "        tokenizer: The trained tokenizer\n",
    "        text: Text to tokenize or list of texts\n",
    "        padding: Whether to pad the sequences\n",
    "        max_length: Maximum length for padding (optional)\n",
    "\n",
    "    Returns:\n",
    "        Encoding object(s) with tokens, ids, etc.\n",
    "    \"\"\"\n",
    "    # Handle both single text and lists of texts\n",
    "    is_single = isinstance(text, str)\n",
    "    texts = [text] if is_single else text\n",
    "\n",
    "    # Configure padding in the tokenizer object itself\n",
    "    if padding:\n",
    "        pad_id = tokenizer.token_to_id(\"<|pad|>\")\n",
    "        if pad_id is not None:\n",
    "            if max_length:\n",
    "                tokenizer.enable_padding(pad_id=pad_id, pad_token=\"<|pad|>\", length=max_length)\n",
    "            else:\n",
    "                tokenizer.enable_padding(pad_id=pad_id, pad_token=\"<|pad|>\")\n",
    "\n",
    "    # Encode text(s)\n",
    "    encodings = tokenizer.encode_batch(texts)\n",
    "\n",
    "    # Display results for single text for demonstration\n",
    "    if is_single:\n",
    "        print(f\"Input text: {text}\")\n",
    "        print(f\"Token IDs: {encodings[0].ids}\")\n",
    "        print(f\"Tokens: {encodings[0].tokens}\")\n",
    "        if padding:\n",
    "            print(f\"Attention mask: {encodings[0].attention_mask}\")\n",
    "\n",
    "        # Decoding demonstration\n",
    "        decoded = tokenizer.decode(encodings[0].ids)\n",
    "        print(f\"Decoded text: {decoded}\")\n",
    "\n",
    "    # Disable padding for future calls if it was temporarily enabled\n",
    "    if padding and max_length:\n",
    "        tokenizer.no_padding()\n",
    "\n",
    "    return encodings[0] if is_single else encodings\n",
    "\n",
    "# def load_pretrained_tokenizer(): # Gives me the GPT-2 pretrained tokenizer\n",
    "#     \"\"\"\n",
    "#     Load the pre-trained GPT-2 tokenizer from Hugging Face\n",
    "\n",
    "#     Returns:\n",
    "#         A pre-trained GPT-2 tokenizer\n",
    "#     \"\"\"\n",
    "#     from transformers import GPT2Tokenizer\n",
    "\n",
    "#     tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "#     tokenizer.pad_token = tokenizer.eos_token  # Set padding token\n",
    "#     return tokenizer\n",
    "\n",
    "\n",
    "# Load the saved tokenizer from the JSON file\n",
    "def load_tokenizer(path):\n",
    "    \"\"\"\n",
    "    Load a previously saved tokenizer from a file\n",
    "\n",
    "    Args:\n",
    "        path: Path to the saved tokenizer JSON file\n",
    "\n",
    "    Returns:\n",
    "        The loaded tokenizer\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer.from_file(path)\n",
    "\n",
    "    # Re-enable padding if needed\n",
    "    pad_id = tokenizer.token_to_id(\"<|pad|>\")\n",
    "    if pad_id is not None:\n",
    "        tokenizer.enable_padding(pad_id=pad_id, pad_token=\"<|pad|>\")\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "# Example usage in a Jupyter Notebook\n",
    "def demonstrate_tokenizer():\n",
    "    \"\"\"\n",
    "    Full demonstration of creating, training, and using a GPT-2 style tokenizer\n",
    "    \"\"\"\n",
    "    # Create a new tokenizer\n",
    "    print(\"Creating tokenizer...\")\n",
    "    tokenizer = create_gpt2_tokenizer()\n",
    "\n",
    "    # Generate some sample texts for demonstration\n",
    "    print(\"Generating sample texts...\")\n",
    "    sample_texts = [\n",
    "        \"This is an example of text that could be used to train a tokenizer.\",\n",
    "        \"It should include diverse vocabulary, punctuation (like commas, periods, question marks?).\",\n",
    "        \"Multiple paragraphs are good to include.\",\n",
    "        \"Numbers like 42, 3.14159, and 2023 should be represented.\",\n",
    "        \"Code snippets might be important if your model will process code:\\ndef hello_world():\\n    print('Hello, world!')\",\n",
    "        # Add more sample texts as needed\n",
    "    ]\n",
    "\n",
    "    # Add some more generated texts for better training\n",
    "    for i in range(50):\n",
    "        words = [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"lazy\", \"dog\",\n",
    "                \"Hello\", \"world\", \"Python\", \"programming\", \"is\", \"fun\", \"GPT\",\n",
    "                \"natural\", \"language\", \"processing\", \"models\", \"work\", \"well\"]\n",
    "        length = random.randint(5, 20)\n",
    "        text = \" \".join(random.choices(words, k=length)) + \".\"\n",
    "        sample_texts.append(text)\n",
    "\n",
    "    # Train the tokenizer on the sample texts\n",
    "    print(f\"Training tokenizer on {len(sample_texts)} texts...\")\n",
    "    tokenizer = train_tokenizer_from_texts(\n",
    "        tokenizer,\n",
    "        sample_texts,\n",
    "        vocab_size=1000,  # Smaller vocab for demo\n",
    "        min_frequency=1,\n",
    "        batch_size=20,\n",
    "        output_dir=\"tokenizer_demo\"\n",
    "    )\n",
    "\n",
    "    # Test the tokenizer\n",
    "    print(\"\\nTesting tokenizer with padding...\")\n",
    "    test_texts = [\n",
    "        \"This is a short text.\",\n",
    "        \"This is a slightly longer text with more content.\",\n",
    "        \"Let's see how padding works on texts of different lengths.\"\n",
    "    ]\n",
    "\n",
    "    # Encode with padding\n",
    "    encodings = use_tokenizer(tokenizer, test_texts, padding=True)\n",
    "\n",
    "    # Display batch results\n",
    "    for i, enc in enumerate(encodings):\n",
    "        print(f\"\\nText {i+1} length: {len(enc.ids)}\")\n",
    "        if hasattr(enc, 'attention_mask'):\n",
    "            print(f\"Attention mask: {enc.attention_mask}\")\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "# Example for loading and using a pre-trained tokenizer\n",
    "def use_pretrained_example():\n",
    "    pretrained = load_pretrained_tokenizer()\n",
    "\n",
    "    sample_text = \"Hello, I'm a language model like GPT-2!\"\n",
    "\n",
    "    # Tokenize with the Transformers tokenizer\n",
    "    tokens = pretrained.tokenize(sample_text)\n",
    "    encoded = pretrained(sample_text, padding=True, return_tensors=\"pt\")\n",
    "    token_ids = encoded[\"input_ids\"][0].tolist()\n",
    "\n",
    "    print(f\"Input text: {sample_text}\")\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    print(f\"Token IDs: {token_ids}\")\n",
    "    print(f\"Decoded text: {pretrained.decode(token_ids)}\")\n",
    "\n",
    "    return pretrained\n",
    "\n",
    "# Run the demonstration if in a Jupyter notebook\n",
    "# Just call demonstrate_tokenizer() in a cell to see the full workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tokenizer...\n",
      "Generating sample texts...\n",
      "Training tokenizer on 55 texts...\n",
      "Preparing 3 batches for training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a692333bd8904232b004813451a937f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokenizer...\n",
      "Tokenizer trained and saved to tokenizer_demo/gpt2_tokenizer.json\n",
      "\n",
      "Testing tokenizer with padding...\n",
      "\n",
      "Text 1 length: 34\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Text 2 length: 34\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Text 3 length: 34\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizer(version=\"1.0\", truncation=None, padding=PaddingParams(strategy=BatchLongest, direction=Right, pad_to_multiple_of=None, pad_id=1, pad_type_id=0, pad_token=\"<|pad|>\"), added_tokens=[{\"id\":0, \"content\":\"<|endoftext|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":1, \"content\":\"<|pad|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}], normalizer=Sequence(normalizers=[NFKC()]), pre_tokenizer=ByteLevel(add_prefix_space=False, trim_offsets=True, use_regex=True), post_processor=ByteLevel(add_prefix_space=True, trim_offsets=False, use_regex=True), decoder=ByteLevel(add_prefix_space=True, trim_offsets=True, use_regex=True), model=BPE(dropout=None, unk_token=None, continuing_subword_prefix=None, end_of_word_suffix=None, fuse_unk=False, byte_fallback=False, ignore_merges=False, vocab={\"<|endoftext|>\":0, \"<|pad|>\":1, \"!\":2, \"'\":3, \"(\":4, \")\":5, \",\":6, \".\":7, \"0\":8, \"1\":9, \"2\":10, \"3\":11, \"4\":12, \"5\":13, \"9\":14, \":\":15, \"<\":16, \">\":17, \"?\":18, \"C\":19, \"G\":20, \"H\":21, \"I\":22, \"M\":23, \"N\":24, \"P\":25, \"T\":26, \"_\":27, \"a\":28, \"b\":29, \"c\":30, \"d\":31, \"e\":32, \"f\":33, \"g\":34, \"h\":35, \"i\":36, \"j\":37, \"k\":38, \"l\":39, \"m\":40, \"n\":41, \"o\":42, \"p\":43, \"q\":44, \"r\":45, \"s\":46, \"t\":47, \"u\":48, \"v\":49, \"w\":50, \"x\":51, \"y\":52, \"z\":53, \"|\":54, \"Ċ\":55, \"č\":56, \"Ġ\":57, \"čĊ\":58, \"el\":59, \"Ġw\":60, \"do\":61, \"ng\":62, \"ro\":63, \"or\":64, \"la\":65, \"Ġla\":66, \"Ġwor\":67, \"ell\":68, \"en\":69, \"ex\":70, \"ra\":71, \"tex\":72, \"text\":73, \"<|\":74, \"ftext\":75, \"pro\":76, \"|>\":77, \"Ġf\":78, \"doftext\":79, \"endoftext\":80, \"ing\":81, \"Ġpro\":82, \"ld\":83, \"is\":84, \"GP\":85, \"GPT\":86, \"qu\":87, \"Ġis\":88, \"ck\":89, \"ick\":90, \"zy\":91, \"ĠGPT\":92, \"Ġworld\":93, \"quick\":94, \"od\":95, \"mp\":96, \"Ġlazy\":97, \"es\":98, ...}, merges=[(\"č\", \"Ċ\"), (\"e\", \"l\"), (\"Ġ\", \"w\"), (\"d\", \"o\"), (\"n\", \"g\"), (\"r\", \"o\"), (\"o\", \"r\"), (\"l\", \"a\"), (\"Ġ\", \"la\"), (\"Ġw\", \"or\"), (\"el\", \"l\"), (\"e\", \"n\"), (\"e\", \"x\"), (\"r\", \"a\"), (\"t\", \"ex\"), (\"tex\", \"t\"), (\"<\", \"|\"), (\"f\", \"text\"), (\"p\", \"ro\"), (\"|\", \">\"), (\"Ġ\", \"f\"), (\"do\", \"ftext\"), (\"en\", \"doftext\"), (\"i\", \"ng\"), (\"Ġ\", \"pro\"), (\"l\", \"d\"), (\"i\", \"s\"), (\"G\", \"P\"), (\"GP\", \"T\"), (\"q\", \"u\"), (\"Ġ\", \"is\"), (\"c\", \"k\"), (\"i\", \"ck\"), (\"z\", \"y\"), (\"Ġ\", \"GPT\"), (\"Ġwor\", \"ld\"), (\"qu\", \"ick\"), (\"o\", \"d\"), (\"m\", \"p\"), (\"Ġla\", \"zy\"), (\"e\", \"s\"), (\"a\", \"t\"), (\"j\", \"u\"), (\"Ġ\", \"m\"), (\"Ġ\", \"quick\"), (\"ell\", \"o\"), (\"mp\", \"s\"), (\"ju\", \"mps\"), (\"H\", \"ello\"), (\"c\", \"es\"), (\"u\", \"n\"), (\"od\", \"el\"), (\"ces\", \"s\"), (\"a\", \"g\"), (\"n\", \"at\"), (\"u\", \"ra\"), (\"u\", \"ag\"), (\"ng\", \"uag\"), (\"Ġm\", \"odel\"), (\"cess\", \"ing\"), (\"nat\", \"ura\"), (\"nguag\", \"e\"), (\"natura\", \"l\"), (\"Ġ\", \"jumps\"), (\"do\", \"g\"), (\"Ġla\", \"nguage\"), (\"Ġf\", \"un\"), (\"Ġmodel\", \"s\"), (\"T\", \"h\"), (\"o\", \"x\"), (\"Ġ\", \"natural\"), (\"Ġpro\", \"cessing\"), (\"Th\", \"e\"), (\"Ġ\", \"Hello\"), (\"Ġ\", \"dog\"), (\"Ġ\", \"The\"), (\"e\", \"r\"), (\"Ġwor\", \"k\"), (\"Ġf\", \"ox\"), (\"g\", \"ra\"), (\"m\", \"m\"), (\"Ġ\", \"b\"), (\"v\", \"er\"), (\"Ġw\", \"ell\"), (\"gra\", \"mm\"), (\"gramm\", \"ing\"), (\"h\", \"o\"), (\"o\", \"ver\"), (\"w\", \"n\"), (\"ro\", \"wn\"), (\"Ġpro\", \"gramming\"), (\"Ġb\", \"rown\"), (\"P\", \"y\"), (\"t\", \"ho\"), (\"Ġ\", \"over\"), (\"Py\", \"tho\"), (\"Pytho\", \"n\"), (\"Ġ\", \"Python\"), (\"w\", \"or\"), ...]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demonstrate_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing 48 batches for training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b19ded734d473bb4c75fc6a0c47b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokenizer...\n",
      "Tokenizer trained and saved to ../models/gpt2_tokenizer.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizer(version=\"1.0\", truncation=None, padding=PaddingParams(strategy=BatchLongest, direction=Right, pad_to_multiple_of=None, pad_id=1, pad_type_id=0, pad_token=\"<|pad|>\"), added_tokens=[{\"id\":0, \"content\":\"<|endoftext|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":1, \"content\":\"<|pad|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}], normalizer=Sequence(normalizers=[NFKC()]), pre_tokenizer=ByteLevel(add_prefix_space=False, trim_offsets=True, use_regex=True), post_processor=ByteLevel(add_prefix_space=True, trim_offsets=False, use_regex=True), decoder=ByteLevel(add_prefix_space=True, trim_offsets=True, use_regex=True), model=BPE(dropout=None, unk_token=None, continuing_subword_prefix=None, end_of_word_suffix=None, fuse_unk=False, byte_fallback=False, ignore_merges=False, vocab={\"<|endoftext|>\":0, \"<|pad|>\":1, \"!\":2, \"\"\":3, \"#\":4, \"$\":5, \"&\":6, \"'\":7, \"(\":8, \")\":9, \"+\":10, \",\":11, \"-\":12, \".\":13, \"/\":14, \"0\":15, \"1\":16, \"2\":17, \"3\":18, \"4\":19, \"5\":20, \"6\":21, \"7\":22, \"8\":23, \"9\":24, \":\":25, \";\":26, \"<\":27, \"=\":28, \">\":29, \"?\":30, \"A\":31, \"B\":32, \"C\":33, \"D\":34, \"E\":35, \"F\":36, \"G\":37, \"H\":38, \"I\":39, \"J\":40, \"K\":41, \"L\":42, \"M\":43, \"N\":44, \"O\":45, \"P\":46, \"Q\":47, \"R\":48, \"S\":49, \"T\":50, \"U\":51, \"V\":52, \"W\":53, \"X\":54, \"Y\":55, \"Z\":56, \"[\":57, \"\\\":58, \"]\":59, \"_\":60, \"a\":61, \"b\":62, \"c\":63, \"d\":64, \"e\":65, \"f\":66, \"g\":67, \"h\":68, \"i\":69, \"j\":70, \"k\":71, \"l\":72, \"m\":73, \"n\":74, \"o\":75, \"p\":76, \"q\":77, \"r\":78, \"s\":79, \"t\":80, \"u\":81, \"v\":82, \"w\":83, \"x\":84, \"y\":85, \"z\":86, \"{\":87, \"|\":88, \"}\":89, \"¡\":90, \"¢\":91, \"£\":92, \"¦\":93, \"¨\":94, \"©\":95, \"®\":96, \"¯\":97, \"±\":98, ...}, merges=[(\"Ġ\", \"t\"), (\"Ġ\", \"c\"), (\"e\", \"n\"), (\"r\", \"e\"), (\"Ġ\", \"a\"), (\"Ġ\", \".\"), (\"t\", \"e\"), (\"č\", \"Ċ\"), (\"o\", \"u\"), (\"Ġ\", \"o\"), (\"a\", \"r\"), (\"Ġt\", \"h\"), (\"a\", \"t\"), (\"e\", \"r\"), (\"Ġ\", \",\"), (\"en\", \"d\"), (\"i\", \"n\"), (\"Ġ\", \"y\"), (\"Ġy\", \"ou\"), (\"a\", \"n\"), (\"x\", \"t\"), (\"Ġc\", \"re\"), (\"f\", \"te\"), (\"u\", \"re\"), (\"o\", \"n\"), (\"end\", \"o\"), (\"<\", \"|\"), (\"|\", \">\"), (\"fte\", \"xt\"), (\"endo\", \"ftext\"), (\"i\", \"t\"), (\"at\", \"ure\"), (\"Ġcre\", \"ature\"), (\"g\", \"e\"), (\"ar\", \"d\"), (\"a\", \"c\"), (\"Ġ\", \"d\"), (\"Ġ\", \"\\\"), (\"r\", \"o\"), (\"Ġ\", \"{\"), (\"Ġ\", \"p\"), (\"Ġth\", \"e\"), (\"i\", \"s\"), (\"Ġo\", \"f\"), (\"Ġt\", \"o\"), (\"s\", \"t\"), (\"Ġa\", \"n\"), (\"l\", \"e\"), (\"Ġ\", \"b\"), (\"ge\", \"t\"), (\"a\", \"y\"), (\"Ġc\", \"ard\"), (\"Ġ\", \"s\"), (\"Ġ\", \"f\"), (\"i\", \"f\"), (\"a\", \"l\"), (\"Ġ\", \"it\"), (\"te\", \"r\"), (\"Ġ\", \"m\"), (\"u\", \"r\"), (\"Ġ\", \"l\"), (\"in\", \"g\"), (\"h\", \"en\"), (\"o\", \"r\"), (\"Ġ\", \"w\"), (\"Ġyou\", \"r\"), (\"Ġo\", \"n\"), (\"ro\", \"l\"), (\"on\", \"t\"), (\"ar\", \"get\"), (\"W\", \"hen\"), (\"Ġc\", \"ont\"), (\"Ġcont\", \"rol\"), (\"Ġ\", \"e\"), (\"ur\", \"n\"), (\"Ġ\", \"u\"), (\"r\", \"a\"), (\"e\", \"l\"), (\"v\", \"e\"), (\"Ġ\", \":\"), (\"Ġ\", \"g\"), (\"Ġ\", \"h\"), (\"an\", \"d\"), (\"i\", \"l\"), (\"Ġt\", \"arget\"), (\"Ġth\", \"is\"), (\"e\", \"s\"), (\"Ġ\", \"S\"), (\"en\", \"t\"), (\"Ġo\", \"r\"), (\"Ġt\", \"urn\"), (\"Ġc\", \"o\"), (\"a\", \"m\"), (\"Ġan\", \"d\"), (\"ter\", \"s\"), (\"Ġ\", \"en\"), (\"Ġu\", \"n\"), (\"Ġ\", \"(\"), (\"i\", \"c\"), ...]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = create_gpt2_tokenizer(vocab_size=8192, min_frequency=2)\n",
    "\n",
    "train_tokenizer_from_texts(tokenizer=tokenizer, texts=data['train']['sentence'], batch_size=512, output_dir=models_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trained_tokenizer = load_tokenizer(models_dir + \"/gpt2_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: {2} {U} : Daring Saboteur can't be blocked this turn . \\n Whenever Daring Saboteur deals combat damage to a player , you may draw a card . If you do , discard a card .\n",
      "Token IDs: [87, 17, 89, 168, 51, 89, 208, 4635, 3816, 1203, 188, 322, 293, 238, 485, 214, 219, 134, 166, 74, 341, 4635, 3816, 1203, 188, 328, 434, 279, 173, 133, 271, 143, 147, 257, 407, 133, 180, 134, 357, 147, 435, 143, 507, 133, 180, 134]\n",
      "Tokens: ['{', '2', '}', 'Ġ{', 'U', '}', 'Ġ:', 'ĠDaring', 'ĠSab', 'ote', 'ur', 'Ġcan', \"'t\", 'Ġbe', 'Ġblocked', 'Ġthis', 'Ġturn', 'Ġ.', 'Ġ\\\\', 'n', 'ĠWhenever', 'ĠDaring', 'ĠSab', 'ote', 'ur', 'Ġdeals', 'Ġcombat', 'Ġdamage', 'Ġto', 'Ġa', 'Ġplayer', 'Ġ,', 'Ġyou', 'Ġmay', 'Ġdraw', 'Ġa', 'Ġcard', 'Ġ.', 'ĠIf', 'Ġyou', 'Ġdo', 'Ġ,', 'Ġdiscard', 'Ġa', 'Ġcard', 'Ġ.']\n",
      "Attention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Decoded text: {2} {U} : Daring Saboteur can't be blocked this turn . \\n Whenever Daring Saboteur deals combat damage to a player , you may draw a card . If you do , discard a card .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=46, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodings = use_tokenizer(trained_tokenizer, data['validation']['sentence'][1], padding=True)\n",
    "encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_tokens(tokenizer, ids):\n",
    "    '''\n",
    "    Convert token IDs back to tokens using the tokenizer\n",
    "    Really just a mapping function for tokenizer.decode()\n",
    "    '''\n",
    "    tokens = tokenizer.decode(encodings.ids)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{2} {U} : Daring Saboteur can't be blocked this turn . \\\\n Whenever Daring Saboteur deals combat damage to a player , you may draw a card . If you do , discard a card .\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_tokens(tokenizer, encodings.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: ['Flash', '\\\\', 'n', 'Other', 'white', 'creatures', 'you', 'control', 'get', '+', '1', '/+', '1', '.', '\\\\', 'n', 'Other', 'blue', 'creatures', 'you', 'control', 'get', '+', '1', '/+', '1', '.']\n"
     ]
    }
   ],
   "source": [
    "# Verify the tokenizer works\n",
    "sample_text = data['validation']['sentence'][0]\n",
    "encoded = tokenizer.encode(sample_text)\n",
    "print(f\"Encoded: {encoded.tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'test', 'of', '\\\\', 't', 'non', 'z', 'ens', 'ic', 'all', 'ical', 'ness', '{', 'U', '}']\n"
     ]
    }
   ],
   "source": [
    "# Test the tokenizer on a string with a tab character and non-sensical text\n",
    "test = tokenizer.encode(\"This is a test of \\\\t nonzensicallicalness {U}\")\n",
    "print(test.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load your Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized model in C:\\Users\\btb51\\Documents\\GitHub\\TCG_Generator\\tcg_generator\\models. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Since you have a pre-trained tokenizer, you can now load it directly\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# tokenizer = Tokenizer.from_file(os.path.join(models_dir, \"tokenizer.json\"))\u001b[39;00m\n\u001b[0;32m      3\u001b[0m modelname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbtb51\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTCG_Generator\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtcg_generator\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# tokenizer.add_special_tokens({'pad_token': '[PAD]'}) # Add the padding token\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:901\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    899\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    904\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[0;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1112\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path):\n\u001b[0;32m   1110\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m CONFIG_MAPPING[pattern]\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[1;32m-> 1112\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have a `model_type` key in its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, or contain one of the following strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min its name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1116\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized model in C:\\Users\\btb51\\Documents\\GitHub\\TCG_Generator\\tcg_generator\\models. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, aria, aria_text, audio-spectrogram-transformer, autoformer, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, colpali, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, depth_pro, deta, detr, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, emu3, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_vl, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, textnet, time_series_transformer, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zamba2, zoedepth"
     ]
    }
   ],
   "source": [
    "# Since you have a pre-trained tokenizer, you can now load it directly\n",
    "# tokenizer = Tokenizer.from_file(os.path.join(models_dir, \"tokenizer.json\"))\n",
    "modelname = r\"C:\\Users\\btb51\\Documents\\GitHub\\TCG_Generator\\tcg_generator\\models\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname, padding=True, truncation=True, max_length=512)\n",
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'}) # Add the padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "tokenizer_path = r\"C:\\Users\\btb51\\Documents\\GitHub\\TCG_Generator\\tcg_generator\\models\\tokenizer.json\"\n",
    "print(\"File exists:\", os.path.exists(tokenizer_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are strange Dungeon and Token cards that are currently as of 2/27/25 not being parsed correctly.  I need to go drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Longest length of oracle text\n",
    "# max_length = max([len(tokenizer.encode(text).ids) for text in corpus_list])\n",
    "max_length = max([len(tokenizer.encode(text).ids) for text in data['train']['sentence']])\n",
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max length is: 1569 on item: 19152 Crash Landing — Search your library for a basic land card , reveal it , put it into your hand , then shuffle . \\n Goblin Camp — Create a Treasure token . \\n Emerald Grove — Create a 2/2 white Knight creature token . \\n Auntie's Teahouse — Scry 3 . \\n Defiled Temple — You may sacrifice a permanent . If you do , draw a card . \\n Mountain Pass — You may put a land card from your hand onto the battlefield . \\n Ebonlake Grotto — Create two 1/1 blue Faerie Dragon creature tokens with flying . \\n Grymforge — For each opponent , goad up to one target creature that player controls . \\n Githyanki Crèche — Distribute three +1/+1 counters among up to three target creatures you control . \\n Last Light Inn — Draw two cards . \\n Reithwin Tollhouse — Roll 2d4 and create that many Treasure tokens . \\n Moonrise Towers — Instant and sorcery spells you cast this turn cost 3 less to cast . \\n Gauntlet of Shar — Each opponent loses 5 life . \\n Balthazar's Lab — Return up to two target creature cards from your graveyard to your hand . \\n Circus of the Last Days — Create a token that's a copy of one of your commanders , except it's not legendary . \\n Undercity Ruins — Create three 4/1 black Skeleton creature tokens with menace . \\n Steel Watch Foundry — You get an emblem with \"Creatures you control get +2/+2 and have trample . \" \\n Ansur's Sanctum — Reveal the top four cards of your library and put them into your hand . Each opponent loses life equal to those cards' total mana value . \\n Temple of Bhaal — Creatures your opponents control get -5/-5 until end of turn .\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for c, item in enumerate(data['train']['sentence']):\n",
    "    if len(item) > max_len:\n",
    "        max_len = len(item)\n",
    "        q = item\n",
    "        card = c\n",
    "\n",
    "print(f'The max length is: {max_len} on item: {card} {q}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Crash Landing — Search your library for a basic land card , reveal it , put it into your hand , then shuffle . \\\\n Goblin Camp — Create a Treasure token . \\\\n Emerald Grove — Create a 2/2 white Knight creature token . \\\\n Auntie\\'s Teahouse — Scry 3 . \\\\n Defiled Temple — You may sacrifice a permanent . If you do , draw a card . \\\\n Mountain Pass — You may put a land card from your hand onto the battlefield . \\\\n Ebonlake Grotto — Create two 1/1 blue Faerie Dragon creature tokens with flying . \\\\n Grymforge — For each opponent , goad up to one target creature that player controls . \\\\n Githyanki Crèche — Distribute three +1/+1 counters among up to three target creatures you control . \\\\n Last Light Inn — Draw two cards . \\\\n Reithwin Tollhouse — Roll 2d4 and create that many Treasure tokens . \\\\n Moonrise Towers — Instant and sorcery spells you cast this turn cost 3 less to cast . \\\\n Gauntlet of Shar — Each opponent loses 5 life . \\\\n Balthazar\\'s Lab — Return up to two target creature cards from your graveyard to your hand . \\\\n Circus of the Last Days — Create a token that\\'s a copy of one of your commanders , except it\\'s not legendary . \\\\n Undercity Ruins — Create three 4/1 black Skeleton creature tokens with menace . \\\\n Steel Watch Foundry — You get an emblem with \"Creatures you control get +2/+2 and have trample . \" \\\\n Ansur\\'s Sanctum — Reveal the top four cards of your library and put them into your hand . Each opponent loses life equal to those cards\\' total mana value . \\\\n Temple of Bhaal — Creatures your opponents control get -5/-5 until end of turn .'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['sentence'][19152]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence'],\n",
       "    num_rows: 24498\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_the_data(examples):\n",
    "    # Initialize lists to store tokenized outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # Process each example\n",
    "    for text in examples['sentence']:\n",
    "        # Encode the text (note: padding is handled by tokenizer configuration)\n",
    "        encoded = tokenizer.encode(text)\n",
    "\n",
    "        # Get input IDs and attention mask\n",
    "        input_ids.append(encoded.ids)\n",
    "        attention_masks.append(encoded.attention_mask)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_masks\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 24498/24498 [00:02<00:00, 8638.65 examples/s] \n",
      "Map: 100%|██████████| 3062/3062 [00:00<00:00, 7994.77 examples/s]\n",
      "Map: 100%|██████████| 3063/3063 [00:00<00:00, 4729.04 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset features: {'sentence': Value(dtype='string', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n",
      "Sample from train: {'sentence': 'Choose one — \\\\n • Destroy target Cleric . \\\\n • Return target Cleric card from your graveyard to your hand . \\\\n • Target player loses 2 life .', 'input_ids': [495, 273, 112, 59, 75, 113, 467, 175, 1202, 16, 59, 75, 113, 456, 175, 1202, 151, 212, 161, 251, 147, 161, 235, 16, 59, 75, 113, 338, 218, 527, 20, 283, 16], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply tokenization to all splits\n",
    "tokenized_dataset = DatasetDict({\n",
    "    'train': data['train'].map(\n",
    "        tokenize_the_data,\n",
    "        # remove_columns=data['train'].column_names, # I want to keep sentence for now\n",
    "        batched=True\n",
    "    ),\n",
    "    'validation': data['validation'].map(\n",
    "        tokenize_the_data,\n",
    "        # remove_columns=data['validation'].column_names,\n",
    "        batched=True\n",
    "    ),\n",
    "    'test': data['test'].map(\n",
    "        tokenize_the_data,\n",
    "        # remove_columns=data['test'].column_names,\n",
    "        batched=True\n",
    "    )\n",
    "})\n",
    "\n",
    "# Verify the tokenization worked\n",
    "print(\"Train dataset features:\", tokenized_dataset['train'].features)\n",
    "print(\"Sample from train:\", tokenized_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 24498\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the tokenized dataset is in the correct format for PyTorch\n",
    "tokenized_dataset.set_format(type='torch', columns=['sentence', 'input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 24498\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3062\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33])\n",
      "torch.Size([15])\n",
      "torch.Size([28])\n",
      "torch.Size([13])\n",
      "torch.Size([74])\n",
      "torch.Size([23])\n",
      "torch.Size([66])\n",
      "torch.Size([38])\n",
      "torch.Size([42])\n",
      "torch.Size([34])\n",
      "torch.Size([22])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 11):\n",
    "    print(tokenized_dataset['train'][i]['input_ids'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([33])\n",
      "torch.Size([15])\n",
      "torch.Size([28])\n",
      "torch.Size([13])\n",
      "torch.Size([74])\n",
      "torch.Size([23])\n",
      "torch.Size([66])\n",
      "torch.Size([38])\n",
      "torch.Size([42])\n",
      "torch.Size([34])\n",
      "torch.Size([22])\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 11):\n",
    "    print(tokenized_dataset['train'][i]['attention_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose one — \\n • Destroy target Cleric . \\n • Return target Cleric card from your graveyard to your hand . \\n • Target player loses 2 life .\n",
      "( {T} : Add {W} or {B} . )\n",
      "Explosive Welcome deals 5 damage to any target and 3 damage to any other target . Add {R} {R} {R} .\n",
      "Vigilance (Attacking doesn't cause this creature to tap . )\n",
      "Trample \\n Alexios , Deimos of Kosmos attacks each combat if able , can't be sacrificed , and can't attack its owner . \\n At the beginning of each player's upkeep , that player gains control of Alexios , untaps it , and puts a +1/+1 counter on it . It gains haste until end of turn .\n",
      "When Gang of Devils dies , it deals 3 damage divided as you choose among one , two , or three targets .\n",
      "Ninjutsu {2} {U} ( {2} {U} , Return an unblocked attacker you control to hand : Put this card onto the battlefield from your hand tapped and attacking . ) \\n Whenever Mist-Syndicate Naga deals combat damage to a player , create a token that's a copy of Mist-Syndicate Naga .\n",
      "Boros Garrison enters tapped . \\n When Boros Garrison enters , return a land you control to its owner's hand . \\n {T} : Add {R} {W} .\n",
      "Enchant creature \\n Enchanted creature can't attack , block , or transform . \\n Sacrifice another permanent : Attach Bound by Moonsilver to target creature . Activate only as a sorcery and only once each turn .\n",
      "During your turn , creatures you control have hexproof . \\n Each creature you control with toughness greater than its power assigns combat damage equal to its toughness rather than its power .\n",
      "Constellation — Whenever an enchantment you control enters , Setessan Skirmisher gets +1/+1 until end of turn .\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 11):\n",
    "    print(tokenized_dataset['train'][i]['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From TensorFlow Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embed_dims, seq_len):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size + 1, embed_dims)\n",
    "        self.pos_embedding = tf.keras.layers.Embedding(seq_len, embed_dims, mask_zero=True)\n",
    "\n",
    "    def compute_mask(self, *args, **kwargs):\n",
    "        return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "    def call(self, x):\n",
    "        index_range = tf.shape(x)[-1]\n",
    "        y = self.embedding(x)\n",
    "        indices = tf.range(index_range)\n",
    "        pos = self.pos_embedding(indices)\n",
    "        return y + pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, key_dim):\n",
    "        super().__init__()\n",
    "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads,\n",
    "            key_dim=key_dim)\n",
    "        \n",
    "    def call(self, x):\n",
    "        y = self.attention(\n",
    "            query=x,\n",
    "            value=x,\n",
    "            key=x,\n",
    "            use_causal_mask=True)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 8912 # Define this based on training data vocab size / tokenize size.\n",
    "# TODO: Or does it need to relate to the tokenizer?\n",
    "SEQUENCE_LENGTH = 500 # Define this based on training data sequence length.\n",
    "EMBEDDING_DIM = 512 # Configure\n",
    "FEED_FORWARD_DIM = 4 * EMBEDDING_DIM # This is usual value used by other LLMs, from below reference.\n",
    "DROPOUT = 0.5 # Configure\n",
    "NUM_HEADS = 16 # Configure\n",
    "NUM_DECODER_LAYERS = 4 # Configure\n",
    "\n",
    "### Reference: https://cameronrwolfe.substack.com/p/decoder-only-transformers-the-workhorse\n",
    "\n",
    "decoder_inputs = tf.keras.Input(shape=(None,), dtype=tf.int64, name=\"decoder_inputs\")\n",
    "positional_embedding = PositionalEmbedding(\n",
    "    VOCAB_SIZE, EMBEDDING_DIM, SEQUENCE_LENGTH)(decoder_inputs)\n",
    "\n",
    "layer_input = positional_embedding\n",
    "layer_output = None\n",
    "for i in range(NUM_DECODER_LAYERS):\n",
    "    decoder_norm_1 = tf.keras.layers.LayerNormalization()(layer_input)\n",
    "    decoder_self_attention = DecoderSelfAttention(NUM_HEADS, EMBEDDING_DIM)(decoder_norm_1)\n",
    "    decoder_add_1 = tf.keras.layers.Add()([decoder_self_attention, decoder_norm_1])\n",
    "    decoder_norm_2 = tf.keras.layers.LayerNormalization()(decoder_add_1)\n",
    "    decoder_feedforward_1 = tf.keras.layers.Dense(FEED_FORWARD_DIM, activation=\"gelu\")(decoder_norm_2)\n",
    "    decoder_feedforward_2 = tf.keras.layers.Dense(EMBEDDING_DIM)(decoder_feedforward_1)\n",
    "    decoder_dropout = tf.keras.layers.Dropout(DROPOUT)(decoder_feedforward_2)\n",
    "    decoder_add_2 = tf.keras.layers.Add()([decoder_dropout, decoder_add_1])\n",
    "\n",
    "    layer_input = decoder_add_2\n",
    "    layer_output = decoder_add_2\n",
    "\n",
    "prediction = tf.keras.layers.Dense(VOCAB_SIZE, activation=\"softmax\")(layer_output)\n",
    "transformer = tf.keras.models.Model(\n",
    "    inputs=decoder_inputs, outputs=prediction, name=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Short Rebuild of the above but with Hugging Face API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might be able to leverage accelerated training by using HF so this could be worth to have.  It also uses a PyTorch backend which I know works on Brandon's system... TensorFlow has been giving me problems in my environment lately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the decoder-only setup\n",
    "from transformers import GPT2Config, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(8912, 512)\n",
       "    (wpe): Embedding(500, 512)\n",
       "    (drop): Dropout(p=0.5, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-3): 4 x GPT2Block(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=1536, nx=512)\n",
       "          (c_proj): Conv1D(nf=512, nx=512)\n",
       "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=2048, nx=512)\n",
       "          (c_proj): Conv1D(nf=512, nx=2048)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.5, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=8912, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE = 8912 # Define this based on training data vocab size / tokenize size.\n",
    "# TODO: Or does it need to relate to the tokenizer?\n",
    "SEQUENCE_LENGTH = 500 # Define this based on training data sequence length. aka. context window\n",
    "EMBEDDING_DIM = 512 # Configure\n",
    "FEED_FORWARD_DIM = 4 * EMBEDDING_DIM # Standard for decoder-only items.\n",
    "DROPOUT = 0.5 # Configure\n",
    "NUM_HEADS = 16 # Configure attention heads\n",
    "NUM_DECODER_LAYERS = 4 # Configure\n",
    "\n",
    "# Define the model configuration\n",
    "model_config = GPT2Config(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    n_positions=SEQUENCE_LENGTH,\n",
    "    n_ctx=SEQUENCE_LENGTH,\n",
    "    n_embd=EMBEDDING_DIM,\n",
    "    n_layer=NUM_DECODER_LAYERS,\n",
    "    n_head=NUM_HEADS,\n",
    "    resid_pdrop=DROPOUT,\n",
    "    embd_pdrop=DROPOUT,\n",
    "    attn_pdrop=DROPOUT,\n",
    "    # layer_norm_epsilon=1e-5,\n",
    "    # initializer_range=0.02,\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "gptmodel = GPT2LMHeadModel(model_config)\n",
    "# Output the model layers for inspection\n",
    "gptmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 17429504\n"
     ]
    }
   ],
   "source": [
    "# How many trainable parameters exist in the gptmodel? (setting p.requires_grad to True for this)\n",
    "trainable_params = sum(p.numel() for p in gptmodel.parameters() if p.requires_grad)\n",
    "print(\"Number of trainable parameters:\", trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight: 4562944 trainable parameters\n",
      "transformer.wpe.weight: 256000 trainable parameters\n",
      "transformer.h.0.ln_1.weight: 512 trainable parameters\n",
      "transformer.h.0.ln_1.bias: 512 trainable parameters\n",
      "transformer.h.0.attn.c_attn.weight: 786432 trainable parameters\n",
      "transformer.h.0.attn.c_attn.bias: 1536 trainable parameters\n",
      "transformer.h.0.attn.c_proj.weight: 262144 trainable parameters\n",
      "transformer.h.0.attn.c_proj.bias: 512 trainable parameters\n",
      "transformer.h.0.ln_2.weight: 512 trainable parameters\n",
      "transformer.h.0.ln_2.bias: 512 trainable parameters\n",
      "transformer.h.0.mlp.c_fc.weight: 1048576 trainable parameters\n",
      "transformer.h.0.mlp.c_fc.bias: 2048 trainable parameters\n",
      "transformer.h.0.mlp.c_proj.weight: 1048576 trainable parameters\n",
      "transformer.h.0.mlp.c_proj.bias: 512 trainable parameters\n",
      "transformer.h.1.ln_1.weight: 512 trainable parameters\n",
      "transformer.h.1.ln_1.bias: 512 trainable parameters\n",
      "transformer.h.1.attn.c_attn.weight: 786432 trainable parameters\n",
      "transformer.h.1.attn.c_attn.bias: 1536 trainable parameters\n",
      "transformer.h.1.attn.c_proj.weight: 262144 trainable parameters\n",
      "transformer.h.1.attn.c_proj.bias: 512 trainable parameters\n",
      "transformer.h.1.ln_2.weight: 512 trainable parameters\n",
      "transformer.h.1.ln_2.bias: 512 trainable parameters\n",
      "transformer.h.1.mlp.c_fc.weight: 1048576 trainable parameters\n",
      "transformer.h.1.mlp.c_fc.bias: 2048 trainable parameters\n",
      "transformer.h.1.mlp.c_proj.weight: 1048576 trainable parameters\n",
      "transformer.h.1.mlp.c_proj.bias: 512 trainable parameters\n",
      "transformer.h.2.ln_1.weight: 512 trainable parameters\n",
      "transformer.h.2.ln_1.bias: 512 trainable parameters\n",
      "transformer.h.2.attn.c_attn.weight: 786432 trainable parameters\n",
      "transformer.h.2.attn.c_attn.bias: 1536 trainable parameters\n",
      "transformer.h.2.attn.c_proj.weight: 262144 trainable parameters\n",
      "transformer.h.2.attn.c_proj.bias: 512 trainable parameters\n",
      "transformer.h.2.ln_2.weight: 512 trainable parameters\n",
      "transformer.h.2.ln_2.bias: 512 trainable parameters\n",
      "transformer.h.2.mlp.c_fc.weight: 1048576 trainable parameters\n",
      "transformer.h.2.mlp.c_fc.bias: 2048 trainable parameters\n",
      "transformer.h.2.mlp.c_proj.weight: 1048576 trainable parameters\n",
      "transformer.h.2.mlp.c_proj.bias: 512 trainable parameters\n",
      "transformer.h.3.ln_1.weight: 512 trainable parameters\n",
      "transformer.h.3.ln_1.bias: 512 trainable parameters\n",
      "transformer.h.3.attn.c_attn.weight: 786432 trainable parameters\n",
      "transformer.h.3.attn.c_attn.bias: 1536 trainable parameters\n",
      "transformer.h.3.attn.c_proj.weight: 262144 trainable parameters\n",
      "transformer.h.3.attn.c_proj.bias: 512 trainable parameters\n",
      "transformer.h.3.ln_2.weight: 512 trainable parameters\n",
      "transformer.h.3.ln_2.bias: 512 trainable parameters\n",
      "transformer.h.3.mlp.c_fc.weight: 1048576 trainable parameters\n",
      "transformer.h.3.mlp.c_fc.bias: 2048 trainable parameters\n",
      "transformer.h.3.mlp.c_proj.weight: 1048576 trainable parameters\n",
      "transformer.h.3.mlp.c_proj.bias: 512 trainable parameters\n",
      "transformer.ln_f.weight: 512 trainable parameters\n",
      "transformer.ln_f.bias: 512 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# Print each parameter's name and trainable count individually\n",
    "for name, param in gptmodel.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.numel()} trainable parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a difference in the reported number of trained parameters between Etienne's custom build and the Hugging Face model.\n",
    "\n",
    "I'm 90% certain it has to do with the positional eoncodings being done slightly different.  48M of his model parameters are from the PosEnc which doesn't show up the same way in the GPT-model.\n",
    "\n",
    "Both models are likely to generate similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Training Args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5, # Prior runs show that I am easily over fitting the data at 25 epochs...\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    # logging_steps=10, # This made my loss vs epoch plot too noisy...\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\btb51\\AppData\\Local\\Temp\\ipykernel_18892\\3291047559.py:5: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Set up the Trainer\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, return_tensors='pt')\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=gptmodel,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tokenizers.Tokenizer' object has no attribute 'pad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the Trainer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\transformers\\trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\transformers\\trainer.py:2500\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2498\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2499\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[1;32m-> 2500\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2501\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[0;32m   2502\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\transformers\\trainer.py:5180\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[1;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[0;32m   5178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[0;32m   5179\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 5180\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m   5181\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   5182\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\accelerate\\data_loader.py:564\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 564\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\transformers\\data\\data_collator.py:271\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 271\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mpad_without_fast_tokenizer_warning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m    280\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\btb51\\miniconda3\\envs\\tcg_generator\\Lib\\site-packages\\transformers\\data\\data_collator.py:59\u001b[0m, in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[1;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# To avoid errors when using Feature extractors\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tokenizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecation_warnings\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m(\u001b[38;5;241m*\u001b[39mpad_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpad_kwargs)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Save the state of the warning, then disable it\u001b[39;00m\n\u001b[0;32m     62\u001b[0m warning_state \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tokenizers.Tokenizer' object has no attribute 'pad'"
     ]
    }
   ],
   "source": [
    "# Run the Trainer\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD CODING WORK:\n",
    "\n",
    "# Set up the Trainer\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True, return_tensors='pt')\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_reduced['train'],\n",
    "    eval_dataset=tokenized_dataset_reduced['validation'],0\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcg_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
